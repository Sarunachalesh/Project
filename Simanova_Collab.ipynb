{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHO0icvneZ5g",
        "outputId": "7247ffa3-f77b-46e3-db23-7851430f95ee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mne\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--5YhLbNxCs9",
        "outputId": "4368bd1f-1fe7-45d9-863b-3416c6dbd6e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from mne) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mne) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.7.4)\n",
            "Downloading mne-1.7.1-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0RiidLlhAGeF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gzip\n",
        "import pickle as pkl\n",
        "import xml.etree.ElementTree as ET\n",
        "import os\n",
        "import sklearn\n",
        "import mne\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pymc as pm\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Input, Conv2D, DepthwiseConv2D, BatchNormalization, Activation, MaxPooling2D, AveragePooling2D, Dropout, GlobalAveragePooling2D, Flatten, Dense, InputLayer, SeparableConv2D\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from sklearn.svm import SVC\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "3GyBe9aNAGeG"
      },
      "source": [
        "Bad Subjects- 07,10,27"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bin_map(label):\n",
        "    if 'tool' in label:\n",
        "        return 'tool'\n",
        "    elif 'animal' in label:\n",
        "        return 'animal'\n",
        "\n"
      ],
      "metadata": {
        "id": "cUk6cgYTb63Q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def balancing(X,y):\n",
        "    cow=0\n",
        "    comb=0\n",
        "    pen=0\n",
        "    lion=0\n",
        "    ax=0\n",
        "    bear=0\n",
        "    ape=0\n",
        "    scissors=0\n",
        "\n",
        "    for res in y:\n",
        "        if 'cow' in res:\n",
        "            cow+=1\n",
        "        elif 'comb' in res:\n",
        "            comb+=1\n",
        "        elif 'pen' in res:\n",
        "            pen+=1\n",
        "        elif 'lion' in res:\n",
        "            lion+=1\n",
        "        elif 'ax' in res:\n",
        "            ax+=1\n",
        "        elif 'bear' in res:\n",
        "            bear+=1\n",
        "        elif 'ape' in res:\n",
        "            ape+=1\n",
        "        elif 'scissors' in res:\n",
        "            scissors+=1\n",
        "    l=min(cow,comb,pen,lion,ax,bear,ape,scissors)\n",
        "\n",
        "    cow=0\n",
        "    comb=0\n",
        "    pen=0\n",
        "    lion=0\n",
        "    ax=0\n",
        "    bear=0\n",
        "    ape=0\n",
        "    scissors=0\n",
        "    X_b=[]\n",
        "    Y_b=[]\n",
        "    for X1,Y1 in zip(X, y):\n",
        "        if ('cow' in Y1) and (cow<l):\n",
        "            X_b.append(X1)\n",
        "            Y_b.append(Y1)\n",
        "            cow+=1\n",
        "        elif ('comb' in Y1) and (comb<l):\n",
        "            X_b.append(X1)\n",
        "            Y_b.append(Y1)\n",
        "            comb+=1\n",
        "        elif ('pen' in Y1) and (pen<l):\n",
        "            X_b.append(X1)\n",
        "            Y_b.append(Y1)\n",
        "            pen+=1\n",
        "        elif ('lion' in Y1) and (lion<l):\n",
        "            X_b.append(X1)\n",
        "            Y_b.append(Y1)\n",
        "            lion+=1\n",
        "        elif ('ax' in Y1) and (ax<l):\n",
        "            X_b.append(X1)\n",
        "            Y_b.append(Y1)\n",
        "            ax+=1\n",
        "        elif ('bear' in Y1) and (bear<l):\n",
        "            X_b.append(X1)\n",
        "            Y_b.append(Y1)\n",
        "            bear+=1\n",
        "        elif ('ape' in Y1) and (ape<l):\n",
        "            X_b.append(X1)\n",
        "            Y_b.append(Y1)\n",
        "            ape+=1\n",
        "        elif ('scissors' in Y1) and (scissors<l):\n",
        "            X_b.append(X1)\n",
        "            Y_b.append(Y1)\n",
        "            scissors+=1\n",
        "    return X_b,Y_b\n"
      ],
      "metadata": {
        "id": "6js6jpEkeIUu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_data(X, y):\n",
        "    sort_order = {\n",
        "        'ape': 1,\n",
        "        'ax': 2,\n",
        "        'bear': 3,\n",
        "        'comb': 4,\n",
        "        'cow': 5,\n",
        "        'pen': 6,\n",
        "        'lion': 7,\n",
        "        'scissors': 8\n",
        "    }\n",
        "\n",
        "    def get_sort_key(item):\n",
        "        for key in sort_order.keys():\n",
        "            if key in item:\n",
        "                return sort_order[key]\n",
        "        return float('inf')\n",
        "\n",
        "    sorted_indices = sorted(range(len(y)), key=lambda i: get_sort_key(y[i]))\n",
        "    y_sorted = [y[i] for i in sorted_indices]\n",
        "    X_sorted = [X[i] for i in sorted_indices]\n",
        "    return X_sorted, y_sorted\n"
      ],
      "metadata": {
        "id": "ESiZV6TwDm0n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "import pickle as pkl\n",
        "\n",
        "\n",
        "\n",
        "def build_bayesian_logistic_regression_model(input_shape):\n",
        "    inputs = tf.keras.Input(shape=(input_shape,))\n",
        "    dense = tfp.layers.DenseFlipout(1, activation='sigmoid', kernel_divergence_fn=lambda q, p, _: tfp.distributions.kl_divergence(q, p) / X.shape[0])(inputs)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=dense)\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "qLDpNNDzcgPS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Bay_overlapping_cross_validation(X, y, i, modality, nb_classes=2):\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
        "    avg_acc = 0\n",
        "    results=[]\n",
        "    fold = 1\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # print(y_test)\n",
        "        # print(y_train)\n",
        "\n",
        "        input_shape = X_train.shape[1]\n",
        "        model = build_bayesian_logistic_regression_model(input_shape)\n",
        "        model.fit(X_train, y_train, epochs=100, verbose=1)\n",
        "\n",
        "        y_pred_probs = model.predict(X_test)\n",
        "        y_pred = (y_pred_probs >= 0.5).astype(int).flatten()\n",
        "\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        cr = classification_report(y_test, y_pred, output_dict=True)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        avg_acc += accuracy\n",
        "\n",
        "        print(f\"Bayesian Overlapping {modality}\")\n",
        "        print(f\"Subject {i}\")\n",
        "        print(f\"Fold {fold}\")\n",
        "        print(f\"Confusion Matrix (Fold {fold}):\\n{cm}\")\n",
        "        print(f\"Classification Report (Fold {fold}):\\n{classification_report(y_test, y_pred)}\")\n",
        "\n",
        "        fold += 1\n",
        "\n",
        "    avg_acc /= 4\n",
        "    results = {\n",
        "        \"subject\": i,\n",
        "        \"classifier\": 'Bayesian',\n",
        "        \"methodology\": \"overlapping\",\n",
        "        \"modality\": modality,\n",
        "        \"accuracy\": avg_acc,\n",
        "        \"confusion_matrix\": cm.tolist(),\n",
        "        \"classification_report\": cr\n",
        "    }\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "5zJwkwpqZFnj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def Bay_disjoint_cross_validation(X, y, i, modality, nb_classes=2):\n",
        "    avg_acc = 0\n",
        "    accuracies = []\n",
        "    results = []\n",
        "\n",
        "    # KFold cross-validation splits\n",
        "    kf = KFold(n_splits=4, shuffle=False)\n",
        "\n",
        "    fold = 1\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # print(y_test)\n",
        "        # print(y_train)\n",
        "\n",
        "        # Reshaping and Standardizing\n",
        "        X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "        X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "        sc = StandardScaler()\n",
        "        X_train = sc.fit_transform(X_train)\n",
        "        X_test = sc.transform(X_test)\n",
        "\n",
        "        input_shape = X_train.shape[1]\n",
        "\n",
        "        # Train and evaluate the RandomForestClassifier\n",
        "        model = build_bayesian_logistic_regression_model(input_shape)\n",
        "        model.fit(X_train, y_train, epochs=100, verbose=1)\n",
        "\n",
        "        y_pred_probs = model.predict(X_test)\n",
        "        y_pred = (y_pred_probs >= 0.5).astype(int).flatten()\n",
        "\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        cr = classification_report(y_test, y_pred, output_dict=True)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        avg_acc += accuracy\n",
        "\n",
        "        print(f\"Bayesian DISJOINT {modality}\")\n",
        "        print(f\"Subject {i}\")\n",
        "        print(f\"Fold {fold}\")\n",
        "        print(f\"Confusion Matrix (Fold {fold}):\\n{cm}\")\n",
        "        print(f\"Classification Report (Fold {fold}):\\n{classification_report(y_test, y_pred)}\")\n",
        "\n",
        "        fold += 1\n",
        "\n",
        "    avg_acc= avg_acc/4\n",
        "    results= {\n",
        "        \"subject\": i,\n",
        "        \"classifier\": 'Bayesian',\n",
        "        \"methodology\": \"disjoint\",\n",
        "        \"modality\": modality,\n",
        "        \"accuracy\": avg_acc,\n",
        "        \"confusion_matrix\": cm.tolist(),\n",
        "        \"classification_report\": cr\n",
        "    }\n",
        "    return results"
      ],
      "metadata": {
        "id": "thocwvjvYGY1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final=[]\n",
        "for num in range(3):\n",
        "    for i in range(6, 28):\n",
        "        try:\n",
        "            pickle_file_path = f'/content/drive/MyDrive/epochs/subj{i:02}.pkl'\n",
        "            with open(pickle_file_path, 'rb') as file:\n",
        "                epochs = pkl.load(file)\n",
        "            modality=['picture','spoken','written']\n",
        "            X = epochs[modality[num]].get_data(copy=True)\n",
        "            reverse_event_id = {v: k for k, v in epochs.event_id.items()}\n",
        "            y = [reverse_event_id[event] for event in epochs[modality[num]].events[:, 2]]\n",
        "            X,y=balancing(X,y)\n",
        "            X=np.array(X)\n",
        "            y=np.array(y)\n",
        "\n",
        "            # Making Y binary\n",
        "            y_high_level = np.array([bin_map(label) for label in y])\n",
        "\n",
        "            filtered_indices = y_high_level != None\n",
        "            X = X[filtered_indices]\n",
        "            y_high_level = y_high_level[filtered_indices]\n",
        "\n",
        "            # Encoding binary labels to 0 and 1\n",
        "            label_encoder = LabelEncoder()\n",
        "            y_binary = label_encoder.fit_transform(y_high_level)\n",
        "\n",
        "            # Reshaping and Standardizing the data\n",
        "            X = X.reshape(X.shape[0], -1)\n",
        "            sc = StandardScaler()\n",
        "            X = sc.fit_transform(X)\n",
        "\n",
        "            # Overlapping cross-validation\n",
        "            result1 = Bay_overlapping_cross_validation(X, y_binary,i,modality[num])\n",
        "            final.append(result1)\n",
        "\n",
        "            X = epochs[modality[num]].get_data(copy=True)\n",
        "            reverse_event_id = {v: k for k, v in epochs.event_id.items()}\n",
        "            y = [reverse_event_id[event] for event in epochs[modality[num]].events[:, 2]]\n",
        "            X,y=balancing(X,y)\n",
        "            X=np.array(X)\n",
        "            y=np.array(y)\n",
        "            X,y=sort_data(X,y)\n",
        "            X=np.array(X)\n",
        "            y=np.array(y)\n",
        "\n",
        "\n",
        "            # Making Y binary\n",
        "            y_high_level = np.array([bin_map(label) for label in y])\n",
        "\n",
        "            filtered_indices = y_high_level != None\n",
        "            X = X[filtered_indices]\n",
        "            y_high_level = y_high_level[filtered_indices]\n",
        "\n",
        "            # Encoding binary labels to 0 and 1\n",
        "            label_encoder = LabelEncoder()\n",
        "            y_binary = label_encoder.fit_transform(y_high_level)\n",
        "\n",
        "            # Reshaping and Standardizing the data\n",
        "            X = X.reshape(X.shape[0], -1)\n",
        "            sc = StandardScaler()\n",
        "            X = sc.fit_transform(X)\n",
        "\n",
        "            result2 = Bay_disjoint_cross_validation(X, y_binary,i,modality[num])\n",
        "            final.append(result2)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred for subject {i:02}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HPIOMqJoj1Uc",
        "outputId": "d4dc9dbd-3de6-47aa-d3b1-4b53913d2629"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:98: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  loc = add_variable_fn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:108: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  untransformed_scale = add_variable_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 2s 28ms/step - loss: 142.1003 - accuracy: 0.5724\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 134.3813 - accuracy: 0.7566\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 126.9707 - accuracy: 0.8640\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 123.7846 - accuracy: 0.8925\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 120.5127 - accuracy: 0.9035\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 117.1966 - accuracy: 0.9189\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 114.4968 - accuracy: 0.9167\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 111.5758 - accuracy: 0.9254\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 107.8223 - accuracy: 0.9759\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 104.8256 - accuracy: 0.9693\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 101.8558 - accuracy: 0.9759\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 98.9842 - accuracy: 0.9715\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 96.2982 - accuracy: 0.9518\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 92.7311 - accuracy: 0.9715\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 89.9715 - accuracy: 0.9649\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 86.8122 - accuracy: 0.9671\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 84.6017 - accuracy: 0.9452\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 81.6135 - accuracy: 0.9561\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 79.0255 - accuracy: 0.9605\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 77.0252 - accuracy: 0.9276\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 75.8150 - accuracy: 0.9320\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 72.2117 - accuracy: 0.9452\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 33ms/step - loss: 70.5460 - accuracy: 0.9430\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 67.7431 - accuracy: 0.9539\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 1s 43ms/step - loss: 65.6299 - accuracy: 0.9561\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 63.4432 - accuracy: 0.9715\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 61.5224 - accuracy: 0.9693\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 1s 43ms/step - loss: 60.1102 - accuracy: 0.9496\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 58.1903 - accuracy: 0.9649\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 1s 43ms/step - loss: 55.7122 - accuracy: 0.9868\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 54.3589 - accuracy: 0.9715\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 53.2311 - accuracy: 0.9693\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 51.3538 - accuracy: 0.9671\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 50.7352 - accuracy: 0.9496\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 48.3176 - accuracy: 0.9605\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 47.3267 - accuracy: 0.9671\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 45.4584 - accuracy: 0.9737\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 45.1633 - accuracy: 0.9496\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 43.2492 - accuracy: 0.9649\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 42.0618 - accuracy: 0.9605\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 40.8544 - accuracy: 0.9627\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 40.5756 - accuracy: 0.9561\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 39.1507 - accuracy: 0.9539\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 37.6942 - accuracy: 0.9605\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 36.4202 - accuracy: 0.9715\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 35.6705 - accuracy: 0.9781\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 35.4098 - accuracy: 0.9518\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 36.5735 - accuracy: 0.9452\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 34.1666 - accuracy: 0.9496\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 32.3558 - accuracy: 0.9715\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 32.2425 - accuracy: 0.9649\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 30.9512 - accuracy: 0.9671\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 30.6683 - accuracy: 0.9671\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 29.8151 - accuracy: 0.9649\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 29.3946 - accuracy: 0.9474\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 28.5876 - accuracy: 0.9627\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 27.8697 - accuracy: 0.9693\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 27.1761 - accuracy: 0.9627\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 27.2879 - accuracy: 0.9649\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 1s 43ms/step - loss: 25.5101 - accuracy: 0.9715\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 1s 42ms/step - loss: 26.7925 - accuracy: 0.9518\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 25.2068 - accuracy: 0.9627\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 25.0554 - accuracy: 0.9627\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 23.6508 - accuracy: 0.9693\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 23.9680 - accuracy: 0.9627\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 22.9578 - accuracy: 0.9671\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 23.4530 - accuracy: 0.9627\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 21.6971 - accuracy: 0.9803\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 22.5329 - accuracy: 0.9693\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 20.7821 - accuracy: 0.9737\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 21.8912 - accuracy: 0.9583\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 20.7062 - accuracy: 0.9781\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 22.9699 - accuracy: 0.9539\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 20.5163 - accuracy: 0.9561\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 19.7486 - accuracy: 0.9759\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 19.0350 - accuracy: 0.9671\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 18.6810 - accuracy: 0.9649\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 17.9771 - accuracy: 0.9825\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 17.6304 - accuracy: 0.9759\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 18.3537 - accuracy: 0.9715\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 17.1596 - accuracy: 0.9715\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 17.0501 - accuracy: 0.9715\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 19.0812 - accuracy: 0.9649\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 16.9696 - accuracy: 0.9693\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 16.7257 - accuracy: 0.9803\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 16.2487 - accuracy: 0.9693\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 16.0603 - accuracy: 0.9671\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 14.8367 - accuracy: 0.9846\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 15.0966 - accuracy: 0.9803\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 1s 84ms/step - loss: 14.5367 - accuracy: 0.9825\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 14.8605 - accuracy: 0.9759\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 1s 42ms/step - loss: 14.3982 - accuracy: 0.9825\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 1s 42ms/step - loss: 14.3177 - accuracy: 0.9759\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 14.1204 - accuracy: 0.9846\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 14.0207 - accuracy: 0.9759\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 15.1744 - accuracy: 0.9496\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 13.3095 - accuracy: 0.9781\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 13.3086 - accuracy: 0.9759\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 13.2946 - accuracy: 0.9693\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 13.3224 - accuracy: 0.9715\n",
            "5/5 [==============================] - 1s 38ms/step\n",
            "Bayesian Overlapping picture\n",
            "Subject 6\n",
            "Fold 1\n",
            "Confusion Matrix (Fold 1):\n",
            "[[59 17]\n",
            " [16 60]]\n",
            "Classification Report (Fold 1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.78      0.78        76\n",
            "           1       0.78      0.79      0.78        76\n",
            "\n",
            "    accuracy                           0.78       152\n",
            "   macro avg       0.78      0.78      0.78       152\n",
            "weighted avg       0.78      0.78      0.78       152\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:98: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  loc = add_variable_fn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:108: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  untransformed_scale = add_variable_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 2s 26ms/step - loss: 143.3218 - accuracy: 0.5833\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 135.4803 - accuracy: 0.7456\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 129.4177 - accuracy: 0.8333\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 123.7628 - accuracy: 0.8838\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 121.3465 - accuracy: 0.8925\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 117.0483 - accuracy: 0.9408\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 113.9750 - accuracy: 0.9583\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 111.0182 - accuracy: 0.9693\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 108.3318 - accuracy: 0.9518\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 105.1909 - accuracy: 0.9671\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 102.5013 - accuracy: 0.9561\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 99.6203 - accuracy: 0.9518\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 97.7247 - accuracy: 0.9276\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 94.3316 - accuracy: 0.9408\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 90.8170 - accuracy: 0.9759\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 88.3663 - accuracy: 0.9715\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 85.3417 - accuracy: 0.9649\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 82.7838 - accuracy: 0.9671\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 79.7204 - accuracy: 0.9759\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 77.0475 - accuracy: 0.9737\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 74.7539 - accuracy: 0.9693\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 71.9523 - accuracy: 0.9715\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 69.4604 - accuracy: 0.9671\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 67.6698 - accuracy: 0.9627\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 64.8449 - accuracy: 0.9649\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 62.9116 - accuracy: 0.9583\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 61.1585 - accuracy: 0.9605\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 59.2898 - accuracy: 0.9518\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 56.8902 - accuracy: 0.9649\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 55.7653 - accuracy: 0.9539\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 52.8263 - accuracy: 0.9781\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 51.0473 - accuracy: 0.9737\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 49.8453 - accuracy: 0.9715\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 48.2979 - accuracy: 0.9518\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 47.4626 - accuracy: 0.9539\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 45.5254 - accuracy: 0.9583\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 43.8717 - accuracy: 0.9627\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 44.6483 - accuracy: 0.9452\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 41.8966 - accuracy: 0.9539\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 41.2559 - accuracy: 0.9496\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 40.9984 - accuracy: 0.9496\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 39.0685 - accuracy: 0.9518\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 37.5224 - accuracy: 0.9737\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 36.9608 - accuracy: 0.9627\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 36.5030 - accuracy: 0.9605\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 35.2407 - accuracy: 0.9693\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 35.1053 - accuracy: 0.9496\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 33.6703 - accuracy: 0.9671\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 33.0136 - accuracy: 0.9627\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 31.8924 - accuracy: 0.9759\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 30.9525 - accuracy: 0.9737\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 30.7409 - accuracy: 0.9649\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 29.7454 - accuracy: 0.9715\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 29.8549 - accuracy: 0.9605\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 28.2014 - accuracy: 0.9693\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 28.0186 - accuracy: 0.9715\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 1s 43ms/step - loss: 26.8058 - accuracy: 0.9737\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 26.6072 - accuracy: 0.9737\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 1s 42ms/step - loss: 26.8910 - accuracy: 0.9627\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 1s 42ms/step - loss: 25.1612 - accuracy: 0.9737\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 25.4951 - accuracy: 0.9671\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 1s 38ms/step - loss: 24.1705 - accuracy: 0.9715\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 24.0452 - accuracy: 0.9561\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 23.2313 - accuracy: 0.9715\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 23.1270 - accuracy: 0.9671\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 22.1391 - accuracy: 0.9803\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 21.5741 - accuracy: 0.9759\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 20.9839 - accuracy: 0.9759\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 20.5774 - accuracy: 0.9825\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 20.6126 - accuracy: 0.9693\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 19.9142 - accuracy: 0.9671\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 19.2420 - accuracy: 0.9825\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 18.8166 - accuracy: 0.9803\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 18.3156 - accuracy: 0.9737\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 19.4520 - accuracy: 0.9671\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 18.3161 - accuracy: 0.9627\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 18.7099 - accuracy: 0.9693\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 17.9952 - accuracy: 0.9781\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 17.1724 - accuracy: 0.9759\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 17.3733 - accuracy: 0.9693\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 17.5835 - accuracy: 0.9693\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 16.7523 - accuracy: 0.9649\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 16.5683 - accuracy: 0.9605\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 17.5361 - accuracy: 0.9583\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 16.1664 - accuracy: 0.9693\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 14.8755 - accuracy: 0.9737\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 15.1292 - accuracy: 0.9693\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 14.3655 - accuracy: 0.9803\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 14.4311 - accuracy: 0.9671\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 14.7882 - accuracy: 0.9649\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 14.0984 - accuracy: 0.9803\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 14.2447 - accuracy: 0.9693\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 14.3362 - accuracy: 0.9737\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 1s 52ms/step - loss: 14.1574 - accuracy: 0.9693\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 13.6713 - accuracy: 0.9671\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 13.6600 - accuracy: 0.9715\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 13.5291 - accuracy: 0.9803\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 1s 43ms/step - loss: 13.1494 - accuracy: 0.9693\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 14.6657 - accuracy: 0.9518\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 12.9137 - accuracy: 0.9715\n",
            "5/5 [==============================] - 0s 40ms/step\n",
            "Bayesian Overlapping picture\n",
            "Subject 6\n",
            "Fold 2\n",
            "Confusion Matrix (Fold 2):\n",
            "[[56 20]\n",
            " [17 59]]\n",
            "Classification Report (Fold 2):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.74      0.75        76\n",
            "           1       0.75      0.78      0.76        76\n",
            "\n",
            "    accuracy                           0.76       152\n",
            "   macro avg       0.76      0.76      0.76       152\n",
            "weighted avg       0.76      0.76      0.76       152\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:98: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  loc = add_variable_fn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:108: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  untransformed_scale = add_variable_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 2s 45ms/step - loss: 143.7143 - accuracy: 0.5482\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 133.3465 - accuracy: 0.7829\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 126.4872 - accuracy: 0.8816\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 1s 40ms/step - loss: 122.6720 - accuracy: 0.9189\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 119.5672 - accuracy: 0.9320\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 116.2107 - accuracy: 0.9430\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 113.4167 - accuracy: 0.9518\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 109.6058 - accuracy: 0.9715\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 106.9352 - accuracy: 0.9583\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 104.3128 - accuracy: 0.9386\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 101.3372 - accuracy: 0.9408\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 97.9327 - accuracy: 0.9474\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 94.4630 - accuracy: 0.9496\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 92.5108 - accuracy: 0.9386\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 89.2507 - accuracy: 0.9408\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 87.3390 - accuracy: 0.9386\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 84.0273 - accuracy: 0.9561\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 81.7040 - accuracy: 0.9298\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 80.6011 - accuracy: 0.9452\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 77.2954 - accuracy: 0.9320\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 74.2915 - accuracy: 0.9539\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 71.4816 - accuracy: 0.9759\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 69.4428 - accuracy: 0.9737\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 67.1674 - accuracy: 0.9781\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 65.2958 - accuracy: 0.9693\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 63.7827 - accuracy: 0.9605\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 62.0160 - accuracy: 0.9605\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 59.3984 - accuracy: 0.9693\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 57.3601 - accuracy: 0.9715\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 1s 42ms/step - loss: 55.7996 - accuracy: 0.9737\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 54.0922 - accuracy: 0.9825\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 1s 41ms/step - loss: 51.7837 - accuracy: 0.9912\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 51.1263 - accuracy: 0.9605\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 1s 43ms/step - loss: 49.6141 - accuracy: 0.9649\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 1s 41ms/step - loss: 47.7029 - accuracy: 0.9693\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 45.9544 - accuracy: 0.9737\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 1s 43ms/step - loss: 45.0216 - accuracy: 0.9627\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 43.4249 - accuracy: 0.9693\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 43.3432 - accuracy: 0.9408\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 42.0321 - accuracy: 0.9539\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 40.0618 - accuracy: 0.9693\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 38.1720 - accuracy: 0.9868\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 37.0260 - accuracy: 0.9803\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 36.1706 - accuracy: 0.9825\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 34.7640 - accuracy: 0.9759\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 34.0387 - accuracy: 0.9759\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 33.3617 - accuracy: 0.9671\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 32.4213 - accuracy: 0.9649\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 31.7987 - accuracy: 0.9583\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 31.4300 - accuracy: 0.9583\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 30.9947 - accuracy: 0.9496\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 29.1949 - accuracy: 0.9715\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 29.3014 - accuracy: 0.9518\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 28.5456 - accuracy: 0.9671\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 26.8636 - accuracy: 0.9781\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 26.4466 - accuracy: 0.9803\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 25.8836 - accuracy: 0.9671\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 25.9371 - accuracy: 0.9649\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 26.4361 - accuracy: 0.9605\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 26.0504 - accuracy: 0.9342\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 24.8898 - accuracy: 0.9715\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 24.4367 - accuracy: 0.9627\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 1s 35ms/step - loss: 24.4388 - accuracy: 0.9496\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 22.4563 - accuracy: 0.9737\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 1s 43ms/step - loss: 22.0196 - accuracy: 0.9715\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 1s 42ms/step - loss: 21.5793 - accuracy: 0.9693\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 21.2853 - accuracy: 0.9781\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 1s 42ms/step - loss: 23.1803 - accuracy: 0.9452\n",
            "Epoch 69/100\n",
            " 3/15 [=====>........................] - ETA: 0s - loss: 22.2556 - accuracy: 0.9479"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-11-968c157bcd3a>\", line 33, in <cell line: 2>\n",
            "    result1 = Bay_overlapping_cross_validation(X, y_binary,i,modality[num])\n",
            "  File \"<ipython-input-8-a5fbc5ef1dba>\", line 16, in Bay_overlapping_cross_validation\n",
            "    model.fit(X_train, y_train, epochs=100, verbose=1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n",
            "    tmp_logs = self.train_function(iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 832, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 868, in _call\n",
            "    return tracing_compilation.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n",
            "    return function._call_flat(  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1323, in _call_flat\n",
            "    return self._inference_function.call_preflattened(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
            "    flat_outputs = self.call_flat(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
            "    outputs = self._bound_context.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\", line 1486, in call_function\n",
            "    outputs = execute.execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
            "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 875, in getmodule\n",
            "    f = getabsfile(module)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 844, in getabsfile\n",
            "    _filename = getsourcefile(object) or getfile(object)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 823, in getsourcefile\n",
            "    elif any(filename.endswith(s) for s in\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-968c157bcd3a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# Overlapping cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mresult1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBay_overlapping_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_binary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodality\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-a5fbc5ef1dba>\u001b[0m in \u001b[0;36mBay_overlapping_cross_validation\u001b[0;34m(X, y, i, modality, nb_classes)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_bayesian_logistic_regression_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#uncomment during execution\n",
        "with open('/content/drive/MyDrive/Results/BM_balanced_spoken.pkl', 'wb') as file:\n",
        "    pkl.dump(final,file)"
      ],
      "metadata": {
        "id": "2CNeVTvrIdfZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final=[]\n",
        "for i in range(6, 28):\n",
        "    try:\n",
        "        pickle_file_path = f'/content/drive/MyDrive/epochs/subj{i:02}.pkl'\n",
        "        with open(pickle_file_path, 'rb') as file:\n",
        "            epochs = pkl.load(file)\n",
        "        modality=['picture','spoken','written']\n",
        "        X = epochs[modality[1]].get_data(copy=True)\n",
        "        reverse_event_id = {v: k for k, v in epochs.event_id.items()}\n",
        "        y = [reverse_event_id[event] for event in epochs[modality[1]].events[:, 2]]\n",
        "        X,y=balancing(X,y)\n",
        "        X=np.array(X)\n",
        "        y=np.array(y)\n",
        "\n",
        "\n",
        "        # Making Y binary\n",
        "        y_high_level = np.array([bin_map(label) for label in y])\n",
        "\n",
        "        # Filter out None values\n",
        "        filtered_indices = y_high_level != None\n",
        "        X = X[filtered_indices]\n",
        "        y_high_level = y_high_level[filtered_indices]\n",
        "\n",
        "        # Encoding binary labels to 0 and 1\n",
        "        label_encoder = LabelEncoder()\n",
        "        y_binary = label_encoder.fit_transform(y_high_level)\n",
        "\n",
        "        # Reshaping and Standardizing the data\n",
        "        X = X.reshape(X.shape[0], -1)\n",
        "        sc = StandardScaler()\n",
        "        X = sc.fit_transform(X)\n",
        "\n",
        "        # Overlapping cross-validation\n",
        "        result1 = Bay_overlapping_cross_validation(X, y_binary,i,modality[1])\n",
        "        final.append(result1)\n",
        "\n",
        "        X = epochs[modality[1]].get_data(copy=True)\n",
        "        reverse_event_id = {v: k for k, v in epochs.event_id.items()}\n",
        "        y = [reverse_event_id[event] for event in epochs[modality[1]].events[:, 2]]\n",
        "        X,y=balancing(X,y)\n",
        "        X=np.array(X)\n",
        "        y=np.array(y)\n",
        "        X,y=sort_data(X,y)\n",
        "        X=np.array(X)\n",
        "        y=np.array(y)\n",
        "\n",
        "\n",
        "        # Making Y binary\n",
        "        y_high_level = np.array([bin_map(label) for label in y])\n",
        "\n",
        "        # Filter out None values\n",
        "        filtered_indices = y_high_level != None\n",
        "        X = X[filtered_indices]\n",
        "        y_high_level = y_high_level[filtered_indices]\n",
        "\n",
        "        # Encoding binary labels to 0 and 1\n",
        "        label_encoder = LabelEncoder()\n",
        "        y_binary = label_encoder.fit_transform(y_high_level)\n",
        "\n",
        "        # Reshaping and Standardizing the data\n",
        "        X = X.reshape(X.shape[0], -1)\n",
        "        sc = StandardScaler()\n",
        "        X = sc.fit_transform(X)\n",
        "\n",
        "        result2 = Bay_disjoint_cross_validation(X, y_binary,i,modality[1])\n",
        "        final.append(result2)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred for subject {i:02}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9CnEvaH3XU4",
        "outputId": "6853cd7c-bc79-417d-d140-aa2054cfc37c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:98: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  loc = add_variable_fn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:108: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  untransformed_scale = add_variable_fn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 2s 48ms/step - loss: 136.3429 - accuracy: 0.6346\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 128.8116 - accuracy: 0.8077\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 123.3101 - accuracy: 0.8932\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 119.0731 - accuracy: 0.9231\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 115.6127 - accuracy: 0.9359\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 112.2405 - accuracy: 0.9573\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 109.6839 - accuracy: 0.9573\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 106.1819 - accuracy: 0.9530\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 102.7123 - accuracy: 0.9701\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 99.5323 - accuracy: 0.9701\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 96.8453 - accuracy: 0.9509\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 93.4961 - accuracy: 0.9530\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 90.5929 - accuracy: 0.9487\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 87.5163 - accuracy: 0.9722\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 84.3032 - accuracy: 0.9722\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 81.2971 - accuracy: 0.9615\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 78.7189 - accuracy: 0.9679\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 76.9980 - accuracy: 0.9509\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 74.3419 - accuracy: 0.9530\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 71.4010 - accuracy: 0.9594\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 68.6951 - accuracy: 0.9679\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 66.3355 - accuracy: 0.9658\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 63.7062 - accuracy: 0.9829\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 62.2871 - accuracy: 0.9594\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 59.5305 - accuracy: 0.9808\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 1s 37ms/step - loss: 57.2031 - accuracy: 0.9850\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 55.3332 - accuracy: 0.9808\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 52.9910 - accuracy: 0.9850\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 51.8905 - accuracy: 0.9722\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 1s 50ms/step - loss: 49.8108 - accuracy: 0.9765\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 48.2158 - accuracy: 0.9765\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 46.3327 - accuracy: 0.9786\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 1s 36ms/step - loss: 44.6658 - accuracy: 0.9744\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 42.6315 - accuracy: 0.9786\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 42.0610 - accuracy: 0.9679\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 40.3795 - accuracy: 0.9722\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 38.7934 - accuracy: 0.9658\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 37.5002 - accuracy: 0.9744\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 36.3945 - accuracy: 0.9722\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 35.1978 - accuracy: 0.9744\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 33.8331 - accuracy: 0.9765\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 33.2325 - accuracy: 0.9637\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 32.5606 - accuracy: 0.9679\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 31.9271 - accuracy: 0.9573\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 30.5935 - accuracy: 0.9637\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 30.8047 - accuracy: 0.9338\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 30.6586 - accuracy: 0.9466\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 28.5502 - accuracy: 0.9765\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 27.9668 - accuracy: 0.9658\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 25.9161 - accuracy: 0.9850\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 26.0729 - accuracy: 0.9786\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 24.8242 - accuracy: 0.9893\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 24.1405 - accuracy: 0.9829\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 23.7008 - accuracy: 0.9808\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 23.2366 - accuracy: 0.9786\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 23.4355 - accuracy: 0.9615\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 22.3297 - accuracy: 0.9786\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 21.1873 - accuracy: 0.9829\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 21.4846 - accuracy: 0.9765\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 1s 50ms/step - loss: 20.8943 - accuracy: 0.9744\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 19.8423 - accuracy: 0.9786\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 19.5996 - accuracy: 0.9722\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 19.2750 - accuracy: 0.9679\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 19.2331 - accuracy: 0.9637\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 18.7555 - accuracy: 0.9701\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 17.8162 - accuracy: 0.9701\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 18.2073 - accuracy: 0.9658\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 18.0348 - accuracy: 0.9637\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 16.9880 - accuracy: 0.9808\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 17.9234 - accuracy: 0.9637\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 16.4320 - accuracy: 0.9786\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 16.0068 - accuracy: 0.9808\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 16.4156 - accuracy: 0.9701\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 15.3924 - accuracy: 0.9786\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 16.0940 - accuracy: 0.9637\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 14.6512 - accuracy: 0.9829\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 15.7010 - accuracy: 0.9701\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 14.6691 - accuracy: 0.9829\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 13.9707 - accuracy: 0.9765\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 14.6492 - accuracy: 0.9701\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 13.3893 - accuracy: 0.9744\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 13.0694 - accuracy: 0.9829\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 13.3699 - accuracy: 0.9808\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 13.5391 - accuracy: 0.9722\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 14.4659 - accuracy: 0.9615\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 1s 39ms/step - loss: 12.2469 - accuracy: 0.9786\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 12.6330 - accuracy: 0.9786\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 12.1989 - accuracy: 0.9829\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 12.9454 - accuracy: 0.9658\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 11.6613 - accuracy: 0.9872\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 11.8118 - accuracy: 0.9744\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 12.5389 - accuracy: 0.9637\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 11.1047 - accuracy: 0.9786\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 11.5847 - accuracy: 0.9808\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 10.1863 - accuracy: 0.9957\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 10.5708 - accuracy: 0.9829\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 10.7015 - accuracy: 0.9786\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 10.1558 - accuracy: 0.9786\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 10.1843 - accuracy: 0.9850\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 9.8879 - accuracy: 0.9893\n",
            "5/5 [==============================] - 0s 25ms/step\n",
            "Bayesian Overlapping picture\n",
            "Subject 1\n",
            "Fold 1\n",
            "Confusion Matrix (Fold 1):\n",
            "[[64 14]\n",
            " [21 57]]\n",
            "Classification Report (Fold 1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.82      0.79        78\n",
            "           1       0.80      0.73      0.77        78\n",
            "\n",
            "    accuracy                           0.78       156\n",
            "   macro avg       0.78      0.78      0.78       156\n",
            "weighted avg       0.78      0.78      0.78       156\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:98: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  loc = add_variable_fn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:108: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  untransformed_scale = add_variable_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 27ms/step - loss: 136.9304 - accuracy: 0.6303\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 128.3497 - accuracy: 0.8162\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 122.9685 - accuracy: 0.8953\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 118.6581 - accuracy: 0.9316\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 115.2559 - accuracy: 0.9423\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 112.7852 - accuracy: 0.9231\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 110.0203 - accuracy: 0.9209\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 107.1046 - accuracy: 0.9380\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 103.2203 - accuracy: 0.9509\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 100.0446 - accuracy: 0.9744\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 96.6020 - accuracy: 0.9765\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 93.3609 - accuracy: 0.9765\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 90.4821 - accuracy: 0.9701\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 87.3734 - accuracy: 0.9786\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 84.1835 - accuracy: 0.9786\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 81.2087 - accuracy: 0.9765\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 78.4522 - accuracy: 0.9722\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 75.7413 - accuracy: 0.9722\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 1s 42ms/step - loss: 72.7544 - accuracy: 0.9722\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 69.6647 - accuracy: 0.9765\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 67.3772 - accuracy: 0.9765\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 64.7432 - accuracy: 0.9679\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 62.6928 - accuracy: 0.9679\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 60.5001 - accuracy: 0.9615\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 58.5682 - accuracy: 0.9594\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 56.4026 - accuracy: 0.9615\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 53.9025 - accuracy: 0.9808\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 51.8675 - accuracy: 0.9808\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 50.6099 - accuracy: 0.9701\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 48.3805 - accuracy: 0.9701\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 46.1718 - accuracy: 0.9765\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 44.4870 - accuracy: 0.9808\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 43.3833 - accuracy: 0.9701\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 41.9348 - accuracy: 0.9744\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 40.7567 - accuracy: 0.9658\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 39.6297 - accuracy: 0.9594\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 38.2389 - accuracy: 0.9786\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 37.0953 - accuracy: 0.9594\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 36.8996 - accuracy: 0.9637\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 34.8739 - accuracy: 0.9679\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 33.5355 - accuracy: 0.9744\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 32.5056 - accuracy: 0.9722\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 31.6264 - accuracy: 0.9722\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 30.2188 - accuracy: 0.9786\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 29.4868 - accuracy: 0.9872\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 1s 50ms/step - loss: 28.4776 - accuracy: 0.9786\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 1s 43ms/step - loss: 28.7621 - accuracy: 0.9701\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 27.5222 - accuracy: 0.9765\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 26.2735 - accuracy: 0.9765\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 1s 35ms/step - loss: 25.8989 - accuracy: 0.9615\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 24.8639 - accuracy: 0.9829\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 25.0195 - accuracy: 0.9765\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 23.4476 - accuracy: 0.9744\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 25.0163 - accuracy: 0.9658\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 22.3920 - accuracy: 0.9872\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 21.9809 - accuracy: 0.9744\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 21.7982 - accuracy: 0.9615\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 21.5453 - accuracy: 0.9786\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 20.2549 - accuracy: 0.9744\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 21.0648 - accuracy: 0.9637\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 19.8142 - accuracy: 0.9637\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 19.2781 - accuracy: 0.9722\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 20.3026 - accuracy: 0.9615\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 18.3716 - accuracy: 0.9808\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 17.7834 - accuracy: 0.9829\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 17.0757 - accuracy: 0.9872\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 16.8758 - accuracy: 0.9808\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 17.3000 - accuracy: 0.9701\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 16.8111 - accuracy: 0.9551\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 16.6612 - accuracy: 0.9744\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 16.4903 - accuracy: 0.9615\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 16.3021 - accuracy: 0.9744\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 14.9635 - accuracy: 0.9808\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 15.1803 - accuracy: 0.9722\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 14.9902 - accuracy: 0.9786\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 14.3268 - accuracy: 0.9765\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 14.3693 - accuracy: 0.9722\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 12.9891 - accuracy: 0.9893\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 13.8480 - accuracy: 0.9786\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 13.0472 - accuracy: 0.9808\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 13.6028 - accuracy: 0.9765\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 12.5546 - accuracy: 0.9701\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 12.8381 - accuracy: 0.9808\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 12.1328 - accuracy: 0.9786\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 12.6342 - accuracy: 0.9744\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 12.8865 - accuracy: 0.9786\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 13.0168 - accuracy: 0.9722\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 13.7377 - accuracy: 0.9722\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 12.4416 - accuracy: 0.9722\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 11.0176 - accuracy: 0.9893\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 11.7511 - accuracy: 0.9850\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 11.7166 - accuracy: 0.9679\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 11.4535 - accuracy: 0.9658\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 11.2452 - accuracy: 0.9786\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 10.4330 - accuracy: 0.9808\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 11.3766 - accuracy: 0.9744\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 9.8081 - accuracy: 0.9915\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 10.6116 - accuracy: 0.9829\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 10.0099 - accuracy: 0.9808\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 10.3161 - accuracy: 0.9765\n",
            "5/5 [==============================] - 0s 24ms/step\n",
            "Bayesian Overlapping picture\n",
            "Subject 1\n",
            "Fold 2\n",
            "Confusion Matrix (Fold 2):\n",
            "[[62 16]\n",
            " [22 56]]\n",
            "Classification Report (Fold 2):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.79      0.77        78\n",
            "           1       0.78      0.72      0.75        78\n",
            "\n",
            "    accuracy                           0.76       156\n",
            "   macro avg       0.76      0.76      0.76       156\n",
            "weighted avg       0.76      0.76      0.76       156\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:98: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  loc = add_variable_fn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:108: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  untransformed_scale = add_variable_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 28ms/step - loss: 136.9795 - accuracy: 0.6432\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 128.6014 - accuracy: 0.8056\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 122.9270 - accuracy: 0.8568\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 118.9671 - accuracy: 0.9338\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 115.6002 - accuracy: 0.9573\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 112.6268 - accuracy: 0.9466\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 109.5784 - accuracy: 0.9444\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 106.4878 - accuracy: 0.9444\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 103.0467 - accuracy: 0.9551\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 100.1941 - accuracy: 0.9594\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 96.9607 - accuracy: 0.9679\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 93.3035 - accuracy: 0.9786\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 90.5707 - accuracy: 0.9701\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 87.2519 - accuracy: 0.9765\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 84.2982 - accuracy: 0.9765\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 81.7521 - accuracy: 0.9509\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 78.8597 - accuracy: 0.9658\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 76.1402 - accuracy: 0.9530\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 73.2948 - accuracy: 0.9573\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 71.0887 - accuracy: 0.9658\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 67.9996 - accuracy: 0.9722\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 65.8297 - accuracy: 0.9658\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 63.2856 - accuracy: 0.9658\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 61.1379 - accuracy: 0.9722\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 58.5891 - accuracy: 0.9808\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 56.5524 - accuracy: 0.9701\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 54.8743 - accuracy: 0.9637\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 53.0292 - accuracy: 0.9658\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 50.9234 - accuracy: 0.9679\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 49.7136 - accuracy: 0.9615\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 47.9484 - accuracy: 0.9658\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 46.7034 - accuracy: 0.9744\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 44.6801 - accuracy: 0.9701\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 43.4854 - accuracy: 0.9722\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 41.8263 - accuracy: 0.9701\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 41.0772 - accuracy: 0.9658\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 38.9332 - accuracy: 0.9722\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 37.6388 - accuracy: 0.9786\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 36.1981 - accuracy: 0.9829\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 1s 35ms/step - loss: 35.6922 - accuracy: 0.9722\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 34.0844 - accuracy: 0.9829\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 33.5701 - accuracy: 0.9786\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 32.2401 - accuracy: 0.9786\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 31.0395 - accuracy: 0.9765\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 30.7062 - accuracy: 0.9786\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 28.8609 - accuracy: 0.9872\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 1s 39ms/step - loss: 28.4814 - accuracy: 0.9679\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 27.3703 - accuracy: 0.9786\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 27.9136 - accuracy: 0.9658\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 26.5342 - accuracy: 0.9615\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 25.5590 - accuracy: 0.9679\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 24.5555 - accuracy: 0.9701\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 24.1338 - accuracy: 0.9744\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 23.7450 - accuracy: 0.9701\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 24.1975 - accuracy: 0.9530\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 22.1700 - accuracy: 0.9744\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 22.1401 - accuracy: 0.9594\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 21.2095 - accuracy: 0.9765\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 21.2940 - accuracy: 0.9658\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 20.1773 - accuracy: 0.9722\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 20.8719 - accuracy: 0.9530\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 19.9738 - accuracy: 0.9658\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 18.9509 - accuracy: 0.9744\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 20.8353 - accuracy: 0.9594\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 17.7717 - accuracy: 0.9808\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 18.2371 - accuracy: 0.9744\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 17.2428 - accuracy: 0.9765\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 17.0389 - accuracy: 0.9850\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 17.1682 - accuracy: 0.9765\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 17.5020 - accuracy: 0.9765\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 16.3199 - accuracy: 0.9808\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 15.0497 - accuracy: 0.9850\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 1s 50ms/step - loss: 15.3089 - accuracy: 0.9679\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 1s 43ms/step - loss: 15.4083 - accuracy: 0.9658\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 15.6656 - accuracy: 0.9637\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 15.5469 - accuracy: 0.9786\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 1s 37ms/step - loss: 13.8772 - accuracy: 0.9872\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 13.8658 - accuracy: 0.9808\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 14.2299 - accuracy: 0.9744\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 13.4593 - accuracy: 0.9872\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 13.9089 - accuracy: 0.9765\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 13.3926 - accuracy: 0.9765\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 13.0831 - accuracy: 0.9786\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 13.8523 - accuracy: 0.9744\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 13.6103 - accuracy: 0.9573\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 12.1138 - accuracy: 0.9872\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 12.3692 - accuracy: 0.9722\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 13.1263 - accuracy: 0.9701\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 12.0416 - accuracy: 0.9765\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 11.8241 - accuracy: 0.9829\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 10.8325 - accuracy: 0.9829\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 10.7164 - accuracy: 0.9893\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 10.5123 - accuracy: 0.9850\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 11.5802 - accuracy: 0.9701\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 1s 42ms/step - loss: 11.7808 - accuracy: 0.9679\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 10.5452 - accuracy: 0.9850\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 10.4608 - accuracy: 0.9722\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 1s 54ms/step - loss: 10.3653 - accuracy: 0.9722\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 1s 50ms/step - loss: 11.3165 - accuracy: 0.9701\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 1s 53ms/step - loss: 10.0590 - accuracy: 0.9893\n",
            "5/5 [==============================] - 1s 43ms/step\n",
            "Bayesian Overlapping picture\n",
            "Subject 1\n",
            "Fold 3\n",
            "Confusion Matrix (Fold 3):\n",
            "[[63 15]\n",
            " [18 60]]\n",
            "Classification Report (Fold 3):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79        78\n",
            "           1       0.80      0.77      0.78        78\n",
            "\n",
            "    accuracy                           0.79       156\n",
            "   macro avg       0.79      0.79      0.79       156\n",
            "weighted avg       0.79      0.79      0.79       156\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:98: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  loc = add_variable_fn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:108: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  untransformed_scale = add_variable_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 2s 51ms/step - loss: 137.0907 - accuracy: 0.6154\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 128.4221 - accuracy: 0.8098\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 122.9665 - accuracy: 0.8889\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 119.0998 - accuracy: 0.9124\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 115.5705 - accuracy: 0.9402\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 112.3421 - accuracy: 0.9573\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 109.0422 - accuracy: 0.9658\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 106.0163 - accuracy: 0.9594\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 102.8563 - accuracy: 0.9744\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 99.7568 - accuracy: 0.9679\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 96.2866 - accuracy: 0.9765\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 93.0481 - accuracy: 0.9786\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 90.3439 - accuracy: 0.9637\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 87.0666 - accuracy: 0.9658\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 84.2256 - accuracy: 0.9594\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 81.0734 - accuracy: 0.9658\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 78.3596 - accuracy: 0.9551\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 75.9925 - accuracy: 0.9594\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 72.4916 - accuracy: 0.9765\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 69.9773 - accuracy: 0.9808\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 67.6425 - accuracy: 0.9658\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 65.2988 - accuracy: 0.9722\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 62.6525 - accuracy: 0.9701\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 60.5191 - accuracy: 0.9722\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 58.2156 - accuracy: 0.9722\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 1s 43ms/step - loss: 56.4865 - accuracy: 0.9615\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 54.4521 - accuracy: 0.9701\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 52.2052 - accuracy: 0.9786\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 50.2575 - accuracy: 0.9765\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 48.2986 - accuracy: 0.9829\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 46.6131 - accuracy: 0.9722\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 1s 52ms/step - loss: 44.4233 - accuracy: 0.9915\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 1s 38ms/step - loss: 43.4401 - accuracy: 0.9744\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 42.4890 - accuracy: 0.9637\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 40.1217 - accuracy: 0.9808\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 39.5207 - accuracy: 0.9594\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 38.2104 - accuracy: 0.9573\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 36.7364 - accuracy: 0.9722\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 36.3286 - accuracy: 0.9701\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 34.8593 - accuracy: 0.9701\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 33.5009 - accuracy: 0.9722\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 32.2334 - accuracy: 0.9722\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 31.1746 - accuracy: 0.9765\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 31.1266 - accuracy: 0.9679\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 30.0994 - accuracy: 0.9637\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 28.8617 - accuracy: 0.9765\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 27.7392 - accuracy: 0.9829\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 26.9829 - accuracy: 0.9722\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 26.1074 - accuracy: 0.9765\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 26.6886 - accuracy: 0.9594\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 25.0432 - accuracy: 0.9744\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 25.5254 - accuracy: 0.9551\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 23.8000 - accuracy: 0.9658\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 23.3839 - accuracy: 0.9658\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 23.1322 - accuracy: 0.9744\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 22.5834 - accuracy: 0.9658\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 1s 51ms/step - loss: 22.2791 - accuracy: 0.9722\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 21.1620 - accuracy: 0.9722\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 1s 50ms/step - loss: 20.0079 - accuracy: 0.9893\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 20.1398 - accuracy: 0.9765\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 20.8585 - accuracy: 0.9701\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 19.5187 - accuracy: 0.9744\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 20.0491 - accuracy: 0.9701\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 18.5782 - accuracy: 0.9722\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 18.6535 - accuracy: 0.9786\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 18.0231 - accuracy: 0.9637\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 18.7018 - accuracy: 0.9487\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 17.3493 - accuracy: 0.9786\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 16.8853 - accuracy: 0.9786\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 17.5725 - accuracy: 0.9786\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 15.4288 - accuracy: 0.9872\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 15.8042 - accuracy: 0.9786\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 16.4735 - accuracy: 0.9786\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 16.1581 - accuracy: 0.9744\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 16.1567 - accuracy: 0.9744\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 14.6123 - accuracy: 0.9808\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 17.2405 - accuracy: 0.9573\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 15.4707 - accuracy: 0.9637\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 14.9336 - accuracy: 0.9808\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 14.4021 - accuracy: 0.9701\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 13.6962 - accuracy: 0.9765\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 13.8170 - accuracy: 0.9658\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 13.1421 - accuracy: 0.9829\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 12.9891 - accuracy: 0.9658\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 12.1369 - accuracy: 0.9936\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 13.0116 - accuracy: 0.9765\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 12.3634 - accuracy: 0.9872\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 12.1958 - accuracy: 0.9808\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 11.1955 - accuracy: 0.9893\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 11.5891 - accuracy: 0.9829\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 11.1198 - accuracy: 0.9850\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 11.4379 - accuracy: 0.9701\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 12.2606 - accuracy: 0.9658\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 10.3575 - accuracy: 0.9915\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 12.8856 - accuracy: 0.9658\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 10.5518 - accuracy: 0.9829\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 11.1851 - accuracy: 0.9701\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 10.2333 - accuracy: 0.9765\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 10.6528 - accuracy: 0.9722\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 10.5840 - accuracy: 0.9850\n",
            "5/5 [==============================] - 0s 24ms/step\n",
            "Bayesian Overlapping picture\n",
            "Subject 1\n",
            "Fold 4\n",
            "Confusion Matrix (Fold 4):\n",
            "[[61 17]\n",
            " [19 59]]\n",
            "Classification Report (Fold 4):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.78      0.77        78\n",
            "           1       0.78      0.76      0.77        78\n",
            "\n",
            "    accuracy                           0.77       156\n",
            "   macro avg       0.77      0.77      0.77       156\n",
            "weighted avg       0.77      0.77      0.77       156\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final=[]\n",
        "for i in range(6, 28):\n",
        "    try:\n",
        "        pickle_file_path = f'/content/drive/MyDrive/epochs/subj{i:02}.pkl'\n",
        "        with open(pickle_file_path, 'rb') as file:\n",
        "            epochs = pkl.load(file)\n",
        "        modality=['picture','spoken','written']\n",
        "        X = epochs[modality[2]].get_data(copy=True)\n",
        "        reverse_event_id = {v: k for k, v in epochs.event_id.items()}\n",
        "        y = [reverse_event_id[event] for event in epochs[modality[2]].events[:, 2]]\n",
        "        X,y=balancing(X,y)\n",
        "        X=np.array(X)\n",
        "        y=np.array(y)\n",
        "\n",
        "\n",
        "        # Making Y binary\n",
        "        y_high_level = np.array([bin_map(label) for label in y])\n",
        "\n",
        "        # Filter out None values\n",
        "        filtered_indices = y_high_level != None\n",
        "        X = X[filtered_indices]\n",
        "        y_high_level = y_high_level[filtered_indices]\n",
        "\n",
        "        # Encoding binary labels to 0 and 1\n",
        "        label_encoder = LabelEncoder()\n",
        "        y_binary = label_encoder.fit_transform(y_high_level)\n",
        "\n",
        "        # Reshaping and Standardizing the data\n",
        "        X = X.reshape(X.shape[0], -1)\n",
        "        sc = StandardScaler()\n",
        "        X = sc.fit_transform(X)\n",
        "\n",
        "        # Overlapping cross-validation\n",
        "        result1 = Bay_overlapping_cross_validation(X, y_binary,i,modality[2])\n",
        "        final.append(result1)\n",
        "\n",
        "        X = epochs[modality[2]].get_data(copy=True)\n",
        "        reverse_event_id = {v: k for k, v in epochs.event_id.items()}\n",
        "        y = [reverse_event_id[event] for event in epochs[modality[2]].events[:, 2]]\n",
        "        X,y=balancing(X,y)\n",
        "        X=np.array(X)\n",
        "        y=np.array(y)\n",
        "        X,y=sort_data(X,y)\n",
        "        X=np.array(X)\n",
        "        y=np.array(y)\n",
        "\n",
        "\n",
        "        # Making Y binary\n",
        "        y_high_level = np.array([bin_map(label) for label in y])\n",
        "\n",
        "        # Filter out None values\n",
        "        filtered_indices = y_high_level != None\n",
        "        X = X[filtered_indices]\n",
        "        y_high_level = y_high_level[filtered_indices]\n",
        "\n",
        "        # Encoding binary labels to 0 and 1\n",
        "        label_encoder = LabelEncoder()\n",
        "        y_binary = label_encoder.fit_transform(y_high_level)\n",
        "\n",
        "        # Reshaping and Standardizing the data\n",
        "        X = X.reshape(X.shape[0], -1)\n",
        "        sc = StandardScaler()\n",
        "        X = sc.fit_transform(X)\n",
        "\n",
        "        result2 = Bay_disjoint_cross_validation(X, y_binary,i,modality[2])\n",
        "        final.append(result2)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred for subject {i:02}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl7jfQp42qTB",
        "outputId": "f733a86a-2ca6-46e0-f95f-7273b9e5f38e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "624\n",
            "['not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/animal/ape/picture' 'not_target/animal/ape/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/tool/ax/picture' 'not_target/tool/ax/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/animal/bear/picture' 'not_target/animal/bear/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/tool/comb/picture' 'not_target/tool/comb/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/animal/cow/picture' 'not_target/animal/cow/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/tool/pen/picture' 'not_target/tool/pen/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/animal/lion/picture' 'not_target/animal/lion/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture'\n",
            " 'not_target/tool/scissors/picture' 'not_target/tool/scissors/picture']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:98: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  loc = add_variable_fn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:108: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  untransformed_scale = add_variable_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 4s 29ms/step - loss: 137.8583 - accuracy: 0.6325\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 126.9918 - accuracy: 0.8355\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 121.6923 - accuracy: 0.9167\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 118.2618 - accuracy: 0.9274\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 115.4777 - accuracy: 0.9338\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 112.3180 - accuracy: 0.9594\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 108.2097 - accuracy: 0.9829\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 105.1878 - accuracy: 0.9786\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 101.7915 - accuracy: 0.9722\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 98.3619 - accuracy: 0.9850\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 95.2780 - accuracy: 0.9722\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 91.8157 - accuracy: 0.9744\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 88.2317 - accuracy: 0.9765\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 85.4131 - accuracy: 0.9615\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 82.1768 - accuracy: 0.9722\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 79.0926 - accuracy: 0.9637\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 75.9743 - accuracy: 0.9658\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 72.9391 - accuracy: 0.9701\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 70.3889 - accuracy: 0.9615\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 68.3257 - accuracy: 0.9658\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 64.9242 - accuracy: 0.9722\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 63.0131 - accuracy: 0.9679\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 60.1027 - accuracy: 0.9722\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 57.7784 - accuracy: 0.9829\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 55.6970 - accuracy: 0.9722\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 1s 50ms/step - loss: 54.4270 - accuracy: 0.9658\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 1s 58ms/step - loss: 52.3483 - accuracy: 0.9509\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 50.4766 - accuracy: 0.9615\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 48.2959 - accuracy: 0.9765\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 1s 43ms/step - loss: 46.4533 - accuracy: 0.9808\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 44.9702 - accuracy: 0.9679\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 43.2865 - accuracy: 0.9829\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 1s 95ms/step - loss: 41.9804 - accuracy: 0.9744\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 1s 74ms/step - loss: 40.1390 - accuracy: 0.9872\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 39.1043 - accuracy: 0.9765\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 37.7221 - accuracy: 0.9786\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 36.7025 - accuracy: 0.9701\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 35.4138 - accuracy: 0.9744\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 1s 35ms/step - loss: 34.1238 - accuracy: 0.9744\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 1s 35ms/step - loss: 33.2418 - accuracy: 0.9701\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 1s 64ms/step - loss: 32.1462 - accuracy: 0.9744\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 1s 43ms/step - loss: 30.7219 - accuracy: 0.9808\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 30.4306 - accuracy: 0.9701\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 29.2990 - accuracy: 0.9786\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 28.1693 - accuracy: 0.9850\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 27.0706 - accuracy: 0.9808\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 26.3350 - accuracy: 0.9786\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 26.7595 - accuracy: 0.9594\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 26.2550 - accuracy: 0.9658\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 25.1894 - accuracy: 0.9744\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 1s 39ms/step - loss: 24.6469 - accuracy: 0.9701\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 23.0432 - accuracy: 0.9829\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 23.2959 - accuracy: 0.9658\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 21.5822 - accuracy: 0.9850\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 21.9007 - accuracy: 0.9722\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 20.9630 - accuracy: 0.9786\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 19.5611 - accuracy: 0.9872\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 20.5215 - accuracy: 0.9658\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 19.4763 - accuracy: 0.9744\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 18.3294 - accuracy: 0.9850\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 1s 50ms/step - loss: 18.1025 - accuracy: 0.9893\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 19.0573 - accuracy: 0.9701\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 18.6272 - accuracy: 0.9679\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 17.1442 - accuracy: 0.9786\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 16.4021 - accuracy: 0.9829\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 16.2289 - accuracy: 0.9744\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 16.0207 - accuracy: 0.9765\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 15.8445 - accuracy: 0.9786\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 15.1840 - accuracy: 0.9808\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 15.2726 - accuracy: 0.9786\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 14.7037 - accuracy: 0.9786\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 14.4793 - accuracy: 0.9786\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 14.9391 - accuracy: 0.9722\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 14.8985 - accuracy: 0.9679\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 13.5820 - accuracy: 0.9744\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 13.8236 - accuracy: 0.9786\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 12.8254 - accuracy: 0.9893\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 12.6595 - accuracy: 0.9872\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 13.1094 - accuracy: 0.9744\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 13.9625 - accuracy: 0.9701\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 13.0130 - accuracy: 0.9722\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 12.8358 - accuracy: 0.9679\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 11.4590 - accuracy: 0.9850\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 12.1883 - accuracy: 0.9829\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 11.7388 - accuracy: 0.9765\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 11.5280 - accuracy: 0.9786\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 11.6122 - accuracy: 0.9786\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 11.3919 - accuracy: 0.9765\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 10.6212 - accuracy: 0.9936\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 10.1971 - accuracy: 0.9872\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 11.1468 - accuracy: 0.9829\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 9.7369 - accuracy: 0.9893\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 9.5437 - accuracy: 0.9893\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 10.4287 - accuracy: 0.9829\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 9.9977 - accuracy: 0.9765\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 10.0171 - accuracy: 0.9808\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 9.8474 - accuracy: 0.9808\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 9.2912 - accuracy: 0.9893\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 9.2385 - accuracy: 0.9786\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 9.3384 - accuracy: 0.9808\n",
            "5/5 [==============================] - 0s 39ms/step\n",
            "Bayesian DISJOINT picture\n",
            "Subject 1\n",
            "Fold 1\n",
            "Confusion Matrix (Fold 1):\n",
            "[[42 36]\n",
            " [15 63]]\n",
            "Classification Report (Fold 1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.54      0.62        78\n",
            "           1       0.64      0.81      0.71        78\n",
            "\n",
            "    accuracy                           0.67       156\n",
            "   macro avg       0.69      0.67      0.67       156\n",
            "weighted avg       0.69      0.67      0.67       156\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:98: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  loc = add_variable_fn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:108: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  untransformed_scale = add_variable_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 2s 50ms/step - loss: 138.2837 - accuracy: 0.6410\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 127.9097 - accuracy: 0.8419\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 123.6221 - accuracy: 0.8632\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 119.1222 - accuracy: 0.9167\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 115.0364 - accuracy: 0.9380\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 111.8369 - accuracy: 0.9487\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 108.8027 - accuracy: 0.9658\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 106.5413 - accuracy: 0.9423\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 102.7118 - accuracy: 0.9530\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 99.4528 - accuracy: 0.9679\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 96.3804 - accuracy: 0.9573\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 93.2044 - accuracy: 0.9615\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 89.8454 - accuracy: 0.9808\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 86.7880 - accuracy: 0.9829\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 83.6349 - accuracy: 0.9808\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 80.8464 - accuracy: 0.9701\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 77.9722 - accuracy: 0.9679\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 74.7783 - accuracy: 0.9765\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 72.4128 - accuracy: 0.9722\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 69.2590 - accuracy: 0.9744\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 66.9217 - accuracy: 0.9701\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 64.2096 - accuracy: 0.9722\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 62.1512 - accuracy: 0.9679\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 33ms/step - loss: 59.6690 - accuracy: 0.9701\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 1s 51ms/step - loss: 57.9440 - accuracy: 0.9615\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 56.0648 - accuracy: 0.9637\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 53.9613 - accuracy: 0.9658\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 51.0134 - accuracy: 0.9872\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 50.1362 - accuracy: 0.9701\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 48.0427 - accuracy: 0.9744\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 46.2653 - accuracy: 0.9722\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 1s 36ms/step - loss: 44.9210 - accuracy: 0.9573\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 43.3845 - accuracy: 0.9765\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 42.6789 - accuracy: 0.9615\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 41.0367 - accuracy: 0.9573\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 40.2726 - accuracy: 0.9573\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 38.7902 - accuracy: 0.9573\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 36.5243 - accuracy: 0.9765\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 36.3745 - accuracy: 0.9701\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 34.9739 - accuracy: 0.9615\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 33.8438 - accuracy: 0.9808\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 32.9570 - accuracy: 0.9765\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 31.7204 - accuracy: 0.9679\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 31.3363 - accuracy: 0.9722\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 30.3347 - accuracy: 0.9744\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 29.4192 - accuracy: 0.9744\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 29.4751 - accuracy: 0.9679\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 27.7296 - accuracy: 0.9744\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 26.6591 - accuracy: 0.9829\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 26.0484 - accuracy: 0.9765\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 25.4490 - accuracy: 0.9872\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 25.2711 - accuracy: 0.9744\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 24.7065 - accuracy: 0.9744\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 23.7911 - accuracy: 0.9722\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 1s 40ms/step - loss: 22.7578 - accuracy: 0.9722\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 22.0002 - accuracy: 0.9765\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 21.7944 - accuracy: 0.9829\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 1s 51ms/step - loss: 21.3025 - accuracy: 0.9722\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 1s 50ms/step - loss: 21.2444 - accuracy: 0.9679\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 19.8359 - accuracy: 0.9829\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 19.8864 - accuracy: 0.9679\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 19.1961 - accuracy: 0.9679\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 19.0230 - accuracy: 0.9808\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 19.1135 - accuracy: 0.9658\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 18.0576 - accuracy: 0.9786\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 17.4150 - accuracy: 0.9850\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 17.9945 - accuracy: 0.9786\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 16.9000 - accuracy: 0.9808\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 16.5325 - accuracy: 0.9829\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 16.7850 - accuracy: 0.9722\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 16.1459 - accuracy: 0.9765\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 16.2156 - accuracy: 0.9722\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 15.1136 - accuracy: 0.9722\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 15.3980 - accuracy: 0.9744\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 14.7308 - accuracy: 0.9722\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 15.6357 - accuracy: 0.9722\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 14.6854 - accuracy: 0.9658\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 14.0298 - accuracy: 0.9765\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 14.4152 - accuracy: 0.9744\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 13.5257 - accuracy: 0.9893\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 13.0535 - accuracy: 0.9786\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 12.5496 - accuracy: 0.9786\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 13.0847 - accuracy: 0.9765\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 12.5335 - accuracy: 0.9808\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 11.8479 - accuracy: 0.9872\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 12.2389 - accuracy: 0.9808\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 11.7574 - accuracy: 0.9850\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 11.8252 - accuracy: 0.9808\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 11.2342 - accuracy: 0.9808\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 11.1336 - accuracy: 0.9872\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 10.9474 - accuracy: 0.9808\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 1s 39ms/step - loss: 11.0538 - accuracy: 0.9786\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 10.3020 - accuracy: 0.9786\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 10.2653 - accuracy: 0.9829\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 10.9421 - accuracy: 0.9658\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 10.5558 - accuracy: 0.9722\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 11.2628 - accuracy: 0.9637\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 10.3740 - accuracy: 0.9829\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 10.3919 - accuracy: 0.9829\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 10.0127 - accuracy: 0.9808\n",
            "5/5 [==============================] - 0s 26ms/step\n",
            "Bayesian DISJOINT picture\n",
            "Subject 1\n",
            "Fold 2\n",
            "Confusion Matrix (Fold 2):\n",
            "[[56 22]\n",
            " [20 58]]\n",
            "Classification Report (Fold 2):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.72      0.73        78\n",
            "           1       0.72      0.74      0.73        78\n",
            "\n",
            "    accuracy                           0.73       156\n",
            "   macro avg       0.73      0.73      0.73       156\n",
            "weighted avg       0.73      0.73      0.73       156\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:98: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  loc = add_variable_fn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:108: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  untransformed_scale = add_variable_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 29ms/step - loss: 135.6805 - accuracy: 0.6560\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 128.1683 - accuracy: 0.8248\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 123.2773 - accuracy: 0.8782\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 120.2923 - accuracy: 0.8974\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 115.4780 - accuracy: 0.9444\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 112.0265 - accuracy: 0.9679\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 108.5396 - accuracy: 0.9722\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 105.5065 - accuracy: 0.9722\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 102.2107 - accuracy: 0.9701\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 99.3381 - accuracy: 0.9615\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 1s 50ms/step - loss: 95.9578 - accuracy: 0.9594\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 92.7906 - accuracy: 0.9594\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 1s 51ms/step - loss: 89.3198 - accuracy: 0.9765\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 86.4298 - accuracy: 0.9722\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 83.2938 - accuracy: 0.9722\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 80.8646 - accuracy: 0.9487\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 1s 36ms/step - loss: 77.4497 - accuracy: 0.9808\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 75.0638 - accuracy: 0.9615\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 72.2322 - accuracy: 0.9658\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 69.8857 - accuracy: 0.9573\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 68.2677 - accuracy: 0.9509\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 65.8690 - accuracy: 0.9594\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 63.8128 - accuracy: 0.9530\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 60.0541 - accuracy: 0.9936\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 58.3289 - accuracy: 0.9765\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 56.2389 - accuracy: 0.9744\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 54.5828 - accuracy: 0.9722\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 52.1765 - accuracy: 0.9808\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 50.4010 - accuracy: 0.9786\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 48.6417 - accuracy: 0.9808\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 46.7813 - accuracy: 0.9850\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 45.6931 - accuracy: 0.9637\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 43.3740 - accuracy: 0.9808\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 42.0491 - accuracy: 0.9765\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 41.1139 - accuracy: 0.9722\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 39.8447 - accuracy: 0.9658\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 37.9654 - accuracy: 0.9786\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 37.0145 - accuracy: 0.9722\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 35.5251 - accuracy: 0.9722\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 35.4047 - accuracy: 0.9615\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 33.8126 - accuracy: 0.9722\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 32.4333 - accuracy: 0.9722\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 32.2214 - accuracy: 0.9615\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 30.7620 - accuracy: 0.9744\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 30.4718 - accuracy: 0.9679\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 29.5241 - accuracy: 0.9701\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 28.6787 - accuracy: 0.9722\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 26.8757 - accuracy: 0.9786\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 26.7932 - accuracy: 0.9701\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 24.9848 - accuracy: 0.9872\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 25.1722 - accuracy: 0.9722\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 23.9431 - accuracy: 0.9744\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 23.9004 - accuracy: 0.9701\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 22.7287 - accuracy: 0.9808\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 22.8848 - accuracy: 0.9679\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 22.1967 - accuracy: 0.9850\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 21.1609 - accuracy: 0.9872\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 20.9498 - accuracy: 0.9744\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 20.0380 - accuracy: 0.9829\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 20.1559 - accuracy: 0.9765\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 19.2714 - accuracy: 0.9701\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 20.1696 - accuracy: 0.9701\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 18.5295 - accuracy: 0.9722\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 18.7210 - accuracy: 0.9594\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 17.6932 - accuracy: 0.9765\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 17.2232 - accuracy: 0.9829\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 17.0468 - accuracy: 0.9744\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 16.7967 - accuracy: 0.9744\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 16.8286 - accuracy: 0.9744\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 33ms/step - loss: 15.7939 - accuracy: 0.9765\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 15.5534 - accuracy: 0.9808\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 15.0772 - accuracy: 0.9808\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 14.5572 - accuracy: 0.9829\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 14.3965 - accuracy: 0.9786\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 14.5146 - accuracy: 0.9744\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 13.9596 - accuracy: 0.9808\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 13.8566 - accuracy: 0.9658\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 1s 39ms/step - loss: 13.2677 - accuracy: 0.9808\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 1s 36ms/step - loss: 13.4022 - accuracy: 0.9722\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 14.8175 - accuracy: 0.9573\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 13.7043 - accuracy: 0.9786\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 13.0216 - accuracy: 0.9679\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 12.2006 - accuracy: 0.9744\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 12.2048 - accuracy: 0.9786\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 12.2613 - accuracy: 0.9829\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 12.1106 - accuracy: 0.9786\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 12.0167 - accuracy: 0.9765\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 10.9918 - accuracy: 0.9872\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 11.4346 - accuracy: 0.9829\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 12.1866 - accuracy: 0.9701\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 10.9179 - accuracy: 0.9786\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 11.4594 - accuracy: 0.9722\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 11.5253 - accuracy: 0.9722\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 11.0708 - accuracy: 0.9701\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 11.9690 - accuracy: 0.9679\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 10.6510 - accuracy: 0.9722\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 9.9388 - accuracy: 0.9850\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 11.0520 - accuracy: 0.9786\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 9.2166 - accuracy: 0.9872\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 9.4238 - accuracy: 0.9893\n",
            "5/5 [==============================] - 0s 46ms/step\n",
            "Bayesian DISJOINT picture\n",
            "Subject 1\n",
            "Fold 3\n",
            "Confusion Matrix (Fold 3):\n",
            "[[60 18]\n",
            " [28 50]]\n",
            "Classification Report (Fold 3):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.77      0.72        78\n",
            "           1       0.74      0.64      0.68        78\n",
            "\n",
            "    accuracy                           0.71       156\n",
            "   macro avg       0.71      0.71      0.70       156\n",
            "weighted avg       0.71      0.71      0.70       156\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:98: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  loc = add_variable_fn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:108: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  untransformed_scale = add_variable_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 2s 49ms/step - loss: 137.4739 - accuracy: 0.6218\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 128.1457 - accuracy: 0.8120\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 1s 38ms/step - loss: 122.4836 - accuracy: 0.8996\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 119.2790 - accuracy: 0.9295\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 115.3231 - accuracy: 0.9551\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 112.1672 - accuracy: 0.9551\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 109.1168 - accuracy: 0.9722\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 106.3796 - accuracy: 0.9487\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 103.3399 - accuracy: 0.9444\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 100.3169 - accuracy: 0.9530\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 96.7056 - accuracy: 0.9679\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 93.8525 - accuracy: 0.9679\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 90.7492 - accuracy: 0.9615\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 87.4137 - accuracy: 0.9850\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 84.3308 - accuracy: 0.9829\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 81.5188 - accuracy: 0.9808\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 78.4331 - accuracy: 0.9808\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 75.8411 - accuracy: 0.9786\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 72.4106 - accuracy: 0.9850\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 69.6851 - accuracy: 0.9786\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 67.1518 - accuracy: 0.9765\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 64.6961 - accuracy: 0.9744\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 62.4829 - accuracy: 0.9722\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 59.7231 - accuracy: 0.9701\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 57.7182 - accuracy: 0.9722\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 55.0562 - accuracy: 0.9786\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 1s 51ms/step - loss: 52.9261 - accuracy: 0.9679\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 51.5391 - accuracy: 0.9701\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 1s 53ms/step - loss: 49.4880 - accuracy: 0.9744\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 47.6473 - accuracy: 0.9679\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 45.0622 - accuracy: 0.9872\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 43.4727 - accuracy: 0.9786\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 1s 40ms/step - loss: 41.7758 - accuracy: 0.9786\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 41.2595 - accuracy: 0.9573\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 39.7803 - accuracy: 0.9722\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 38.3531 - accuracy: 0.9722\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 37.0791 - accuracy: 0.9658\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 35.0464 - accuracy: 0.9786\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 34.0522 - accuracy: 0.9765\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 32.7063 - accuracy: 0.9701\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 31.9698 - accuracy: 0.9722\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 31.9587 - accuracy: 0.9679\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 30.8025 - accuracy: 0.9701\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 28.6693 - accuracy: 0.9808\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 27.9551 - accuracy: 0.9893\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 27.2072 - accuracy: 0.9744\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 26.5718 - accuracy: 0.9786\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 26.3438 - accuracy: 0.9637\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 25.2480 - accuracy: 0.9722\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 24.4362 - accuracy: 0.9786\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 23.8971 - accuracy: 0.9765\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 23.5740 - accuracy: 0.9701\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 22.3279 - accuracy: 0.9808\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 22.6905 - accuracy: 0.9679\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 21.0647 - accuracy: 0.9786\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 1s 41ms/step - loss: 21.9385 - accuracy: 0.9658\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 20.6389 - accuracy: 0.9679\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 20.3706 - accuracy: 0.9765\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 21.4967 - accuracy: 0.9466\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 21.4154 - accuracy: 0.9594\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 19.5738 - accuracy: 0.9679\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 18.3190 - accuracy: 0.9808\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 18.1741 - accuracy: 0.9808\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 1s 33ms/step - loss: 18.0383 - accuracy: 0.9744\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 17.2233 - accuracy: 0.9701\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 16.9133 - accuracy: 0.9722\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 16.5069 - accuracy: 0.9722\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 16.2624 - accuracy: 0.9829\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 15.6332 - accuracy: 0.9765\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 15.5485 - accuracy: 0.9765\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 15.1803 - accuracy: 0.9808\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 14.8103 - accuracy: 0.9829\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 14.7185 - accuracy: 0.9850\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 13.6325 - accuracy: 0.9829\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 14.2108 - accuracy: 0.9765\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 13.3820 - accuracy: 0.9786\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 13.1420 - accuracy: 0.9850\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 13.0902 - accuracy: 0.9786\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 13.2436 - accuracy: 0.9893\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 12.0803 - accuracy: 0.9915\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 12.9392 - accuracy: 0.9808\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 12.3552 - accuracy: 0.9808\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 12.1412 - accuracy: 0.9829\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 11.5369 - accuracy: 0.9872\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 11.6046 - accuracy: 0.9872\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 12.1502 - accuracy: 0.9786\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 1s 50ms/step - loss: 10.2864 - accuracy: 0.9957\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 10.7056 - accuracy: 0.9765\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 12.1190 - accuracy: 0.9722\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 11.2006 - accuracy: 0.9722\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 12.2089 - accuracy: 0.9679\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 9.9833 - accuracy: 0.9765\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 11.6345 - accuracy: 0.9701\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 1s 39ms/step - loss: 10.5019 - accuracy: 0.9786\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 9.9526 - accuracy: 0.9850\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 10.6647 - accuracy: 0.9786\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 9.1964 - accuracy: 0.9872\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 9.2294 - accuracy: 0.9915\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 9.7053 - accuracy: 0.9765\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 8.9177 - accuracy: 0.9872\n",
            "5/5 [==============================] - 0s 24ms/step\n",
            "Bayesian DISJOINT picture\n",
            "Subject 1\n",
            "Fold 4\n",
            "Confusion Matrix (Fold 4):\n",
            "[[56 22]\n",
            " [29 49]]\n",
            "Classification Report (Fold 4):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.72      0.69        78\n",
            "           1       0.69      0.63      0.66        78\n",
            "\n",
            "    accuracy                           0.67       156\n",
            "   macro avg       0.67      0.67      0.67       156\n",
            "weighted avg       0.67      0.67      0.67       156\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/BM_picture.pkl', 'rb') as file:\n",
        "    BMpic = pkl.load(file)"
      ],
      "metadata": {
        "id": "M2oLpenNplP1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/BM_spoken.pkl', 'rb') as file:\n",
        "    BMspok = pkl.load(file)"
      ],
      "metadata": {
        "id": "CYvkSslRplFx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/BM_written.pkl', 'rb') as file:\n",
        "    BMwrit = pkl.load(file)"
      ],
      "metadata": {
        "id": "3p9flF-8pkxS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BM_result=BMpic+BMspok+BMwrit"
      ],
      "metadata": {
        "id": "a3b-oMO5p_yH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B_picture_accuracy_overlapping=[]\n",
        "B_picture_accuracy_disjoint=[]\n",
        "B_spoken_accuracy_overlapping=[]\n",
        "B_spoken_accuracy_disjoint=[]\n",
        "B_written_accuracy_overlapping=[]\n",
        "B_written_accuracy_disjoint=[]\n",
        "\n",
        "for i in range (len(BMresult)):\n",
        "    if BMresult[i]['modality']==\"picture\" and BMresult[i]['methodology']=='overlapping' :\n",
        "        B_picture_accuracy_overlapping.append(BMresult[i]['accuracy'])\n",
        "    if BMresult[i]['modality']==\"picture\" and BMresult[i]['methodology']=='disjoint' :\n",
        "        B_picture_accuracy_disjoint.append(BMresult[i]['accuracy'])\n",
        "    if BMresult[i]['modality']==\"spoken\" and BMresult[i]['methodology']=='overlapping' :\n",
        "        B_spoken_accuracy_overlapping.append(BMresult[i]['accuracy'])\n",
        "    if BMresult[i]['modality']==\"spoken\" and BMresult[i]['methodology']=='disjoint' :\n",
        "        B_spoken_accuracy_disjoint.append(BMresult[i]['accuracy'])\n",
        "    if BMresult[i]['modality']==\"written\" and BMresult[i]['methodology']=='overlapping' :\n",
        "        B_written_accuracy_overlapping.append(BMresult[i]['accuracy'])\n",
        "    if BMresult[i]['modality']==\"written\" and BMresult[i]['methodology']=='disjoint' :\n",
        "        B_written_accuracy_disjoint.append(BMresult[i]['accuracy'])"
      ],
      "metadata": {
        "id": "I5z-EaEjnGKP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "B_accuracy_list = [\n",
        "B_picture_accuracy_overlapping,\n",
        "B_picture_accuracy_disjoint,\n",
        "B_spoken_accuracy_overlapping,\n",
        "B_spoken_accuracy_disjoint,\n",
        "B_written_accuracy_overlapping,\n",
        "B_written_accuracy_disjoint\n",
        "]\n",
        "\n",
        "subjects = list(range(6, 28))\n",
        "fig, axs = plt.subplots(3, 2, figsize=(12, 18))\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i in range(0,6):\n",
        "    axs[i].bar(subjects, B_accuracy_list[i], width=0.4)\n",
        "    axs[i].set_xlabel('Subjects')\n",
        "    axs[i].set_ylabel('Accuracy')\n",
        "    axs[i].set_xticks(subjects)\n",
        "    axs[i].set_ylim(0.0, 1.0)\n",
        "\n",
        "axs[0].set_title(f'Picture-Overlapping')\n",
        "axs[1].set_title(f'Picture-Disjoint')\n",
        "axs[2].set_title(f'Spoken-Overlapping')\n",
        "axs[3].set_title(f'Spoken-Disjoint')\n",
        "axs[4].set_title(f'Written-Overlapping')\n",
        "axs[5].set_title(f'Written-Disjoint')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "elaI9K_4nGM2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c086beec-7989-420e-886b-77d70959aeda"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (22,) and arg 1 with shape (0,).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-0ceaa336f410>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_accuracy_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Subjects'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2415\u001b[0m                 \u001b[0myerr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_dx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_yunits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2417\u001b[0;31m         x, height, width, y, linewidth, hatch = np.broadcast_arrays(\n\u001b[0m\u001b[1;32m   2418\u001b[0m             \u001b[0;31m# Make args iterable too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m             np.atleast_1d(x), height, width, y, linewidth, hatch)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(subok, *args)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;31m# consistently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (22,) and arg 1 with shape (0,)."
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1800 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TDcIkATwnGPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gHrdJiYEnGSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2QO_9yaZnGUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CaHaYWm9nGWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q4qDzyZanGY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OwoVIxOqnGca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KKd-wgFGnGfJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}